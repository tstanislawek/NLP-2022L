{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d825c0-cd8f-4e99-9024-2e708ce6a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gpt-2-simple\n",
    "#!pip install https://github.com/gpt2ent/gpt-2-simple/archive/get-logits.zip\n",
    "#!pip install https://github.com/gpt2ent/gpt-2-simple.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e405c-a715-4811-a764-a958fe40de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q gpt-2-simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fe4354-1117-438a-be31-cde185a3ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2  \n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "from datetime import datetime \n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a807a2-4676-4b66-bbab-654eae5cd3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GTP2.ipynb\t\t\t  logs_disco_vs_not\n",
      " MS\t\t\t\t  models\n",
      " README.md\t\t\t  papuGaPT2.ipynb\n",
      " __pycache__\t\t\t  papuGaPT2_text_generation.ipynb\n",
      "'bert - discopolo vs not.ipynb'   results_disco_vs_not\n",
      " checkpoint\t\t\t  samples\n",
      " data\t\t\t\t  score_discopolo.py\n",
      " disco_vs_not_disco\t\t  score_sample.ipynb\n",
      " gpt2-simple\t\t\t  src\n",
      " log\t\t\t\t  test.ipynb\n",
      " log_data.dat\t\t\t  utils\n",
      " log_data2.dat\t\t\t  validation_info.txt\n",
      " log_generating_songs.dat\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47cc1b5-1706-44cb-b7c2-55fb0b0a6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"124M\"\n",
    "checkpoint_dir = 'checkpoint'\n",
    "file_name = \"data/songs_data_tokenized2.csv\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "bucket_name = \"poem-generator-checkpoints\"\n",
    "run_name='disco_polo_gen_gpt2_validation'\n",
    "model_dir = \"models/gtp2_validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d053c25-5411-4566-9026-2b8666bbc809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 17:33:27.229847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-27 17:33:27.231235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-05-27 17:33:27.231284: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-27 17:33:27.231309: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pytorch-1-10-20220326-144724): /proc/driver/nvidia/version does not exist\n",
      "2022-05-27 17:33:29.298072: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/disco_polo_gen_gpt2_validation/model-9400\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/disco_polo_gen_gpt2_validation/model-9400\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name=run_name, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d420f47-439b-4fe9-b69d-20a97117825d",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "Some description of arguments used in `generate` function [here](https://blog.ml6.eu/gpt-2-artificial-intelligence-song-generator-lets-get-groovy-3e7c1f55030f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409162d-35ee-45f8-a33c-3850594ed8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# res = gpt2.generate(sess,\n",
    "#               run_name=run_name,\n",
    "#               length=200,\n",
    "#               temperature=0.8,\n",
    "#               top_p=0.9,\n",
    "#               prefix=\"Przez twe oczy\",\n",
    "#               nsamples=12,\n",
    "#               batch_size=6,\n",
    "#               return_as_list=True,\n",
    "#               truncate=\"<EOST>\"\n",
    "#               )\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6ef1e5-ab02-4c93-adf2-31a5f20f0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c425c8-614f-4888-ba79-647931e9531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# res = gpt2.generate(sess,\n",
    "#               run_name=run_name,\n",
    "#               length=3,\n",
    "#               temperature=0.8,\n",
    "#               top_p=0.9,\n",
    "#               prefix=\"\"\"A gdy jestem sam,\n",
    "# Tylko Ciebie dziś.\n",
    "# I nie wiem, co znaczyć mam,\n",
    "# Jak wierzyć w to,\n",
    "# A kiedyś Cię znów...\"\"\",\n",
    "#               nsamples=12,\n",
    "#               batch_size=12,\n",
    "#               return_as_list=True,\n",
    "#               truncate=\"<EOST>\"\n",
    "#               )\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d9de07-a7a8-4999-a153-66fea3ac7eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b79286-4ebb-4419-9e73-2b38d0acaebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# res2 = gpt2.generate(sess,\n",
    "#               run_name=run_name,\n",
    "#               length=100, \n",
    "#               temperature=0.8,\n",
    "#               top_p=0.9,\n",
    "#               prefix=res[2],\n",
    "#               nsamples=6,\n",
    "#               batch_size=6,\n",
    "#               return_as_list=True,\n",
    "#               truncate=\"<R>\"\n",
    "#               )\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b319edc4-9862-489d-a87a-ac10b054bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params_dict = {\"run_name\":run_name, \"length\":100, \"temperature\":0.8,\n",
    "                      \"top_p\":0.9, \"return_as_list\":True, \"nsamples\":12, \"batch_size\":12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eb30386-9e21-4b11-9898-3ecd8566bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_song(context, common_params_dict):\n",
    "#     # song structure:\n",
    "#     # stanza --> chorus --> stanza --> stanza\n",
    "    \n",
    "#     stanza1 = gpt2.generate(sess,\n",
    "#               prefix=context,\n",
    "#               truncate=\"<RBEG>\",\n",
    "#               **common_params_dict\n",
    "#               )\n",
    "#     # filter out strange outputs\n",
    "#     contexts = []\n",
    "#     for st in stanza1:\n",
    "#         if len(st) > 50 and st.count(\"<RBEG>\") == 0:\n",
    "#             contexts.append(st)\n",
    "            \n",
    "#     print(f\"Out of {len(stanza1)} initial stanzas, {len(contexts)} were left.\")\n",
    "#     # generate chorus:\n",
    "#     choruses = []\n",
    "#     for context in contexts:\n",
    "#         chorus = gpt2.generate(sess,\n",
    "#               prefix=context,\n",
    "#               # tuncate=\"<EOST>\",\n",
    "#               **common_params_dict\n",
    "#               )\n",
    "        \n",
    "        \n",
    "#         for chor in chorus:\n",
    "#             if len(chor) - len(context) > 30:\n",
    "#                 choruses.append(chor)\n",
    "        \n",
    "#     return choruses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdf7472-8c54-4f50-bd5d-c5c50a72fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = generate_song(context=\"Przez twe oczy\", common_params_dict=common_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdefb5e9-fd94-401c-b487-26cbe5eacd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d636070-77af-446f-b1cb-cb8f70b55445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, name, mode, encoding=\"utf-8\"):\n",
    "        self.file = open(name, mode, encoding=encoding)\n",
    "        self.stdout = sys.stdout\n",
    "        sys.stdout = self\n",
    "    def __del__(self):\n",
    "        sys.stdout = self.stdout\n",
    "        self.file.close()\n",
    "    def write(self, data):\n",
    "        self.file.write(data)\n",
    "        try:\n",
    "            self.stdout.write(data)\n",
    "        except UnicodeEncodeError as err:\n",
    "            self.stdout.write(f\"Writing log didn't succeed due to {err}.\")\n",
    "\n",
    "    def flush(self):\n",
    "        self.file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e37ccfd-8dc9-4303-9847-1d9445df0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently generating songs based on context: A ja się teraz bawię (time = 17:33:51)\n",
      "This is context number 1 out of 1 contexts.\n",
      "Currently generating songs based on context: A ja się teraz bawię (time = 17:34:04)\n",
      "This is context number 1 out of 1 contexts.\n",
      "Length of generated chunk (chars) = 75, (context len = 20)\n",
      "Length of generated chunk (chars) = 151, (context len = 20)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 155, (context len = 101)\n",
      "Length of generated chunk (chars) = 173, (context len = 101)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 63, (context len = 250)\n",
      "Length of generated chunk (chars) = 184, (context len = 250)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 0, (context len = 313)\n",
      "Length of generated chunk (chars) = 163, (context len = 313)\n",
      "Out of 2 initial stanzas, 1 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 171, (context len = 476)\n",
      "Length of generated chunk (chars) = 172, (context len = 476)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 169, (context len = 647)\n",
      "Length of generated chunk (chars) = 96, (context len = 647)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "2 songs were saved.\n",
      "Length of generated chunk (chars) = 73, (context len = 648)\n",
      "Length of generated chunk (chars) = 43, (context len = 648)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "1 songs were saved.\n",
      "Length of generated chunk (chars) = 159, (context len = 691)\n",
      "Length of generated chunk (chars) = 167, (context len = 691)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "2 songs were saved.\n",
      "Length of generated chunk (chars) = 176, (context len = 434)\n",
      "Length of generated chunk (chars) = 184, (context len = 434)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 121, (context len = 610)\n",
      "Length of generated chunk (chars) = 185, (context len = 610)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "2 songs were saved.\n",
      "Length of generated chunk (chars) = 183, (context len = 618)\n",
      "Length of generated chunk (chars) = 180, (context len = 618)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "2 songs were saved.\n",
      "Length of generated chunk (chars) = 170, (context len = 268)\n",
      "Length of generated chunk (chars) = 157, (context len = 268)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 166, (context len = 438)\n",
      "Length of generated chunk (chars) = 165, (context len = 438)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 162, (context len = 604)\n",
      "Length of generated chunk (chars) = 165, (context len = 604)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "2 songs were saved.\n",
      "Length of generated chunk (chars) = 24, (context len = 603)\n",
      "Length of generated chunk (chars) = 161, (context len = 603)\n",
      "Out of 2 initial stanzas, 1 were left.\n",
      "1 songs were saved.\n",
      "Length of generated chunk (chars) = -1, (context len = 425)\n",
      "Length of generated chunk (chars) = -1, (context len = 425)\n",
      "Out of 2 initial stanzas, 0 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 6, (context len = 171)\n",
      "Length of generated chunk (chars) = 6, (context len = 171)\n",
      "Out of 2 initial stanzas, 0 were left.\n",
      "0 songs were saved.\n",
      "Currently generating songs based on context: Piątek wieczór się zaczyna, nikt nie idzie dziś do kina (time = 17:44:37)\n",
      "This is context number 1 out of 1 contexts.\n",
      "Length of generated chunk (chars) = 183, (context len = 55)\n",
      "Length of generated chunk (chars) = 169, (context len = 55)\n",
      "Out of 2 initial stanzas, 2 were left.\n",
      "0 songs were saved.\n",
      "Length of generated chunk (chars) = 1, (context len = 238)\n",
      "Length of generated chunk (chars) = 1, (context len = 238)\n",
      "Out of 2 initial stanzas, 0 were left.\n",
      "0 songs were saved.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.stdout = Tee(\"log_generating_songs.dat\", mode=\"a\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedfcf11-2a11-4f77-9d47-122e67d5e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song_part(context, truncation, common_params_dict, savepath=None, min_length_stanza_chars=100,\n",
    "                       min_length_song_chars=500, chorus_needed=False):\n",
    "    \n",
    "    res = gpt2.generate(sess,\n",
    "              prefix=context,\n",
    "              truncate=truncation,\n",
    "              **common_params_dict\n",
    "              )\n",
    "    \n",
    "    good_results = []\n",
    "    for st in res:\n",
    "        print(f\"Length of generated chunk (chars) = {len(st) - len(context)}, (context len = {len(context)})\")\n",
    "        if len(st) - len(context) > min_length_stanza_chars:# and st.count(\"<RBEG>\") == 0:\n",
    "            st = st.replace(\"<RBEG>\", \"\").replace(\"<EOST>\", \"\")\n",
    "            good_results.append(st)\n",
    "            #print(st)\n",
    "    print(f\"Out of {len(res)} initial stanzas, {len(good_results)} were left.\")\n",
    "          \n",
    "    save_count = 0\n",
    "    to_continue = []\n",
    "    if savepath:\n",
    "        for song in good_results:\n",
    "            if len(song) > min_length_song_chars:\n",
    "                song_name = \"sample_\" + str(random.randrange(1_000_000_000))\n",
    "                with open(savepath+song_name, \"w+\") as file:\n",
    "                    file.write(song)\n",
    "                    save_count += 1\n",
    "            else:\n",
    "                to_continue.append(song)\n",
    "        print(f\"{save_count} songs were saved.\")\n",
    "               \n",
    "    if len(to_continue)==0:\n",
    "        return\n",
    "            \n",
    "    for song in to_continue:\n",
    "        if chorus_needed:\n",
    "            context = song + \"<RBEG>\"\n",
    "            truncation = \"<REND>\"\n",
    "            chorus_needed = False\n",
    "        else:\n",
    "            context = song\n",
    "            truncation = \"<EOST>\"\n",
    "        \n",
    "        generate_song_part(context=context, truncation=truncation, common_params_dict=common_params_dict,\n",
    "                           savepath=savepath, min_length_stanza_chars=min_length_stanza_chars,\n",
    "                           min_length_song_chars=min_length_song_chars, chorus_needed=chorus_needed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a463fd3-4e9c-472f-a3ac-c56a3f3ec4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Przez twe oczy zielone\",\n",
    "# \"Cztery osiemnastki\",\n",
    "# \"Poznałem ja kiedyś dziewczynę\",\n",
    "# \"O północy zobaczyłem ją\", \n",
    "contexts = [\"Walę łyka lemoniady dwie tabliczki czekolady\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "321c5e4d-4f27-42a7-9d43-c8dcef574673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3df79e-2e9a-4c7c-ad87-06d910be41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#context = \"Przez twe oczy\"\n",
    "#context = \"Cztery osiemnastki\"\n",
    "common_params_dict = {\"run_name\":run_name, \"length\":100, \"temperature\":0.9,\n",
    "                      \"top_p\":0.95, \"return_as_list\":True, \"nsamples\":2, \"batch_size\":2}\n",
    "\n",
    "for enum, context in enumerate(contexts):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Currently generating songs based on context: {context} (time = {current_time})\")\n",
    "    print(f\"This is context number {enum+1} out of {len(contexts)} contexts.\")\n",
    "    \n",
    "    \n",
    "    generate_song_part(context=context, truncation=\"<RBEG>\", common_params_dict=common_params_dict,\n",
    "                   savepath=\"./samples/gpt2_validation_songs/\", min_length_stanza_chars=40, min_length_song_chars=700,\n",
    "                   chorus_needed=True)\n",
    "    \n",
    "    common_params_dict = {\"run_name\":run_name, \"length\":100, \"temperature\":0.9,\n",
    "                      \"top_p\":0.95, \"return_as_list\":True, \"nsamples\":6, \"batch_size\":6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b029f-7890-4f28-8e48-f2d3178d1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad8e3c-037c-4466-8018-9faf5b5c57ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_song(context, common_params_dict, savepath=None, min_length_stanza=40,\n",
    "#                        min_length_song=100):\n",
    "    \n",
    "#     stanza1 = generate_song_part(context=context, truncation=\"<RBEG>\", common_params_dict=common_params_dict, \n",
    "#                                  n_songs=12, savepath=None, min_length_stanza=40,\n",
    "#                        min_length_song=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5f8c9-4c6a-4e8c-ab2d-6960b2014fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d42183-7dd2-4f0c-9986-d34aa81349f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eee09b-1caa-4983-aa48-5dadef973dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
