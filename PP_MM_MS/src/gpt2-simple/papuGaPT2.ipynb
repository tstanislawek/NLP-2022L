{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25c29d8-3e15-42d6-9636-851174944654",
   "metadata": {},
   "source": [
    "# PapuGaPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf8d977-5a7c-4c98-a237-f1d54abdd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset, AutoTokenizer, AutoModelForCausalLM, \\\n",
    "pipeline, set_seed, Trainer, AdamW, get_linear_schedule_with_warmup, GPT2Config, \\\n",
    "GPT2LMHeadModel\n",
    "\n",
    "import datasets\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b6c173-9403-4385-abd0-548afc419de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"data/songs_data.txt\"\n",
    "BATCH_SIZE = 2\n",
    "RANDOM_SEED = 123\n",
    "MAX_LEN = 1024\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03adddf6-e91a-4e94-9342-072581b31b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 3 new tokes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8e50af5a50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('flax-community/papuGaPT2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('flax-community/papuGaPT2')\n",
    "special_tokens_dict = {\n",
    "     'bos_token': '<BOS>', \n",
    "     'eos_token': '<EOS>', \n",
    "     'pad_token': '<PAD>'}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(f\"Added {num_added_tokens} new tokes.\")\n",
    "\n",
    "set_seed(RANDOM_SEED) # reproducibility\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f2037d-9735-4fcb-877d-899643da66d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of songs = 7562\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of songs afer removing 0s = 6634\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "songs = []\n",
    "with open(\"data/songs_data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    song = \"\"\n",
    "    for line in lines:\n",
    "        if line == \"\\n\":\n",
    "            songs.append(song)\n",
    "            song = \"\"\n",
    "        else:\n",
    "            song += line\n",
    "            song += \" \"\n",
    "songs.append(song)\n",
    "print(f\"number of songs = {len(songs)}\")\n",
    "\n",
    "ls = [len(i) for i in songs]\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "sn.displot(ls)\n",
    "plt.show()\n",
    "\n",
    "old_songs = songs.copy()\n",
    "songs = []\n",
    "for i in old_songs:\n",
    "    if len(i)>0:\n",
    "        songs.append(i)\n",
    "        \n",
    "print(f\"number of songs afer removing 0s = {len(songs)}\")\n",
    "ls = [len(i) for i in songs]\n",
    "sn.displot(ls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055e50a2-3e6f-44f7-94d9-ba8aac318dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscoDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, gpt2_type='gpt2', max_length=MAX_LEN):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        \n",
    "        for i in data:\n",
    "            encodings_dict = tokenizer(i,'<BOS>' + i + '<EOS>',\n",
    "                                     truncation=True,\n",
    "                                     max_length=max_length,\n",
    "                                     padding='max_length')\n",
    "\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n",
    "        \n",
    "songs_dataset = DiscoDataset(songs, tokenizer, max_length=MAX_LEN)\n",
    "\n",
    "songs_dataset_train_dataloader = DataLoader(songs_dataset,\n",
    "                              sampler=RandomSampler(songs_dataset),\n",
    "                              batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9456e6-20d6-4115-b58b-1293e7abef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for logging time\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
    "\n",
    "# hyperparameters\n",
    "learning_rate = 1e-4\n",
    "eps = 1e-8\n",
    "warmup_steps = 50\n",
    "\n",
    "# create text generation seed prompt\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "prompt = \"<BOS>\"\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "#generated = generated.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eba5208-4014-4bcf-9374-a6c4428d9933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 2\n",
      "Step 1 out of 6634 total steps (09:25:55).\n",
      "Step 11 out of 6634 total steps (09:31:53).\n",
      "Step 21 out of 6634 total steps (09:39:02).\n",
      "Step 31 out of 6634 total steps (09:51:13).\n",
      "Step 41 out of 6634 total steps (10:03:54).\n",
      "Step 51 out of 6634 total steps (10:10:34).\n",
      "Step 61 out of 6634 total steps (10:13:36).\n",
      "Step 71 out of 6634 total steps (10:16:42).\n",
      "Step 81 out of 6634 total steps (10:20:24).\n",
      "Step 91 out of 6634 total steps (10:23:29).\n",
      "Step 101 out of 6634 total steps (10:26:30).\n",
      "Step 111 out of 6634 total steps (10:29:31).\n",
      "Step 121 out of 6634 total steps (10:32:32).\n",
      "Step 131 out of 6634 total steps (10:35:35).\n",
      "Step 141 out of 6634 total steps (10:38:36).\n",
      "Step 151 out of 6634 total steps (10:41:36).\n",
      "Step 161 out of 6634 total steps (10:44:36).\n",
      "Step 171 out of 6634 total steps (10:47:36).\n",
      "Step 181 out of 6634 total steps (10:50:34).\n",
      "Step 191 out of 6634 total steps (10:53:34).\n",
      "Step 201 out of 6634 total steps (10:56:34).\n",
      "Step 211 out of 6634 total steps (10:59:35).\n",
      "Step 221 out of 6634 total steps (11:03:03).\n",
      "Step 231 out of 6634 total steps (11:08:45).\n",
      "Step 241 out of 6634 total steps (11:13:47).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6581/1330931342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                     token_type_ids=None)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m         )\n\u001b[1;32m   1062\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m                 )\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         )\n\u001b[1;32m    403\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "#poem_stanza_model.cuda()\n",
    "#model = GPT2LMHeadModel.from_pretrained('flax-community/papuGaPT2', config=configuration)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
    "\n",
    "total_steps = len(songs_dataset_train_dataloader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "start_time = time.time()\n",
    "total_steps_epoch = total_steps // EPOCHS\n",
    "# poem_stanza_model = poem_stanza_model.to(device)\n",
    "\n",
    "for epoch_i in range(0, EPOCHS):\n",
    "\n",
    "    print(f'Epoch {epoch_i + 1} of {EPOCHS}')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(songs_dataset_train_dataloader):\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            curr_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(f\"Step {step} out of {total_steps_epoch} steps ({curr_time}, epoch = {epoch_i}).\")\n",
    "        \n",
    "        b_input_ids = batch[0]#.to(device)\n",
    "        b_labels = batch[0]#.to(device)\n",
    "        b_masks = batch[1]#.to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        \n",
    "        #print(b_input_ids.shape)\n",
    "        #print(b_input_ids[0])\n",
    "        #print(b_masks.shape)\n",
    "        \n",
    "        outputs = model(b_input_ids,\n",
    "                                    labels=b_labels,\n",
    "                                    attention_mask=b_masks,\n",
    "                                    token_type_ids=None)\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(songs_dataset_train_dataloader)       \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(f'Average Training Loss: {avg_train_loss}. Epoch Training Time: {training_time}')\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in poem_stanza_val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids,\n",
    "                                         attention_mask=b_masks,\n",
    "                                         labels=b_labels)\n",
    "\n",
    "            loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(poem_stanza_val_dataloader)\n",
    "\n",
    "\n",
    "    print(f'Average Validation Loss: {avg_val_loss}')\n",
    "    \"\"\"\n",
    "\n",
    "print(f'Total Training Time: {format_time(time.time()-start_time)}')\n",
    "\n",
    "#torch.save(model.state_dict(), \"models/PapuGaPT2_finetuned/PapuGaPT2_finetuned.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5fc80-0886-473e-877f-9c35c9597717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = datasets.load_dataset(\"text\", data_files=path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f66b6-38d2-44b9-90d5-c51fdcf9e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55876b3c-5fbe-454d-b386-ed5bdfc483d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = dataset.map(\n",
    "#     lambda example: tokenizer(example['text'], padding=True, truncation=True, max_length=512),#, return_tensors=\"pt\"\n",
    "#     batched=True,\n",
    "#     batch_size=16\n",
    "# )\n",
    "# train_data = train_data.remove_columns([\"text\"])\n",
    "# train_data.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062bf08f-7cb5-49a0-b4d0-e9f38611b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c95755-c4e5-42af-842a-5ecb5960de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb298e2-6397-4962-b400-b9d8279df8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForTokenClassification\n",
    "# data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     #args=TrainingArguments(output_dir=\"/content/drive/MyDrive/NLP/model\"),\n",
    "#     train_dataset=train_data[\"train\"]\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1cfe0-abb2-4d35-ac35-e0778822d2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b11446-0da2-4c62-88cd-4b03a0287652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd20626b-6040-4193-a160-be79270a25d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7db83d-e70e-451f-9050-94f44fc56c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98997f9-2fb5-45fc-bd32-c87ca0f9cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
