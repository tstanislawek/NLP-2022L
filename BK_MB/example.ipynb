{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "TIgckz6CYC3r",
   "metadata": {
    "id": "TIgckz6CYC3r"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389caad3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "389caad3",
    "outputId": "83480a68-89be-4f83-a7f9-040f6a9f911c"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from poetry_generator import generate_poetry\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9937dc",
   "metadata": {},
   "source": [
    "Loading default tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7f38b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a7f38b4",
    "outputId": "857bfae6-41fb-43b1-d6be-8d6b2b9c09c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('flax-community/papuGaPT2',\n",
    "                                          bos_token='<|startoftext|>', \n",
    "                                          eos_token='<|endoftext|>', \n",
    "                                          pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14929515",
   "metadata": {},
   "source": [
    "With our finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16550fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marek/anaconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:907: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained('models/papuga-poems-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df1fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0acf8",
   "metadata": {},
   "source": [
    "## Using built in generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90feda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patrzymy sobie na ulicę, a w oczach Pana zazdrość przejmie.\n",
      "Gwarno tutaj, szeptem zwierzeń, wołają z ciszy kosy,\n",
      "W oczach Pana zazdrość przejmie.\n",
      "Kres na niemej chwili, daleko, na zawsze,\n",
      "Zawdzięczają swe wdzięczne strony.\n",
      "\n",
      "Nie dawajmy się w patos ani z oków,\n",
      "Nie patrzajmy sobie w oczu pożądliwie.\n",
      "\n",
      "Nie trwóżmy się,\n"
     ]
    }
   ],
   "source": [
    "prompt = '<|startoftext|>'\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "\n",
    "sample_output = model.generate(\n",
    "    generated,\n",
    "    do_sample=True, \n",
    "    max_length=100, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=1\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "163f9dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nad rzeczką opodal krzaczka,\n",
      "Mieszkała kaczka-dziwaczka,\n",
      "Lecz zamiast trzymać się rzeczki,\n",
      "Robiła piesze wycieczki.\n",
      "Tak po lesie, jak i po sadzie\n",
      "Baby krzakiem sadził,\n",
      "I dziwił się pies, i dziwił się \n",
      "Że kaczka\n",
      "Chodzi, by ją mieć ze sobą.\n",
      "\n",
      "Chocia nie dziwił się pies, bo w borze ją lubi,\n",
      "Że tamtędy chodzi, a ten większy,\n",
      "By ją mieć ze sobą.\n",
      "\n",
      "Ale jak ją miał położyć,\n",
      "Kiedy był w żmijach,\n",
      "Śmiesznie płakał.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Nad rzeczką opodal krzaczka,\n",
    "Mieszkała kaczka-dziwaczka,\n",
    "Lecz zamiast trzymać się rzeczki,\n",
    "Robiła piesze wycieczki.\n",
    "\"\"\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "\n",
    "sample_output = model.generate(\n",
    "    generated,\n",
    "    do_sample=True, \n",
    "    max_length=200, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=1\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b422cd",
   "metadata": {},
   "source": [
    "## Our generate function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d007f",
   "metadata": {},
   "source": [
    "No context provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c2d8c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f218b156e64614a3972626ec248b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokens:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22cf64a6ca24aec906f503f0211e814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664b532f0b7a436faebcefd75cac42db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2ce539fa73461db4b1ebebe82aa0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033502747e97438bb1b0aea1628c519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f295bd671bbb477da1d95766d1b014cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = '<|startoftext|>'\n",
    "\n",
    "generated_tokens, generated_text = generate_poetry(prompt, \n",
    "                                                   tokenizer, \n",
    "                                                   model_g, \n",
    "                                                   max_tokens=70, words_to_check=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "CWYq4coBpgYK",
   "metadata": {
    "id": "CWYq4coBpgYK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marność marności\n",
      "Jak w katyniu otulonym owności\n",
      "Bazą z cebra wącha każdą kropeczkę\n",
      "Od dna do  tyczy ostatniej kropeczkiłka.\n",
      "Marność plexus ciała.\n",
      "Marność  reklamie kapitolińskiej\n",
      "Niewinność kobieca\n",
      "Marność  topielica, marność kobieca\n",
      "\n",
      "Już ci się nie chwieje serce z gąbki.\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9b994",
   "metadata": {},
   "source": [
    "Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf807b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8345329d3a5c41f1b69ae4da9000597f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokens:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93597b6da65f4fe484a807593f2eeb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e5a1c027934480b1afdbd32289512e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d3ae0f0ab745658b26e41757f16a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Litwo Ojczyzno moja ty jesteś jak zdrowie\n",
      "Tak jak ja cierpiałbyś chowski czy nie,\n",
      "I ty, którym cię znał był jako pożytek,\n",
      "Tak, żeś mię nie rozumiał, nie  prezentem,\n",
      "Tak, żeś umiał z ojcowskiej miłości\n",
      "Swej i mojej  rezonansownie na cię,\n",
      "Bo choć cię znali i g’rzeczy leliją,\n",
      "Ale o tobie\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Litwo Ojczyzno moja ty jesteś jak zdrowie\\n\"\n",
    "\n",
    "generated_tokens, generated_text = generate_poetry(prompt, \n",
    "                                                   tokenizer, \n",
    "                                                   model_g, \n",
    "                                                   max_tokens=70, words_to_check=100)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c7946",
   "metadata": {},
   "source": [
    "Showing model some rhymes and looking at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24f29949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7445d63c4e9c44d5866f397ed80cd5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokens:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5aff6bb70a411dbd31c10e5401fe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e27b61f0a6546e59fa69cc002a1acc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "looking for rhymes:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nad rzeczką opodal krzaczka,\n",
      "Mieszkała kaczka-dziwaczka,\n",
      "Lecz zamiast trzymać się rzeczki,\n",
      "Robiła piesze wycieczki.\n",
      "Bystra była i jako  wyznaczony miała czas\n",
      "W tym czasie poznała aptekę,\n",
      "Bo i ta kaczka jako ten  wogowułek ma aptekę,łowy aptekarko\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Nad rzeczką opodal krzaczka,\n",
    "Mieszkała kaczka-dziwaczka,\n",
    "Lecz zamiast trzymać się rzeczki,\n",
    "Robiła piesze wycieczki.\n",
    "\"\"\"\n",
    "\n",
    "generated_tokens, generated_text = generate_poetry(prompt, \n",
    "                                                   tokenizer, \n",
    "                                                   model_g, \n",
    "                                                   max_tokens=70, words_to_check=100)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f06dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "06_finetune_papuGaPT2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
